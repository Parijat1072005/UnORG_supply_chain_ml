{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGw71q220n8m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyrlRei20xmh",
    "outputId": "5e345463-a3de-4a6a-f61a-b98edfcda209"
   },
   "outputs": [],
   "source": [
    "# --- Load Data ---\n",
    "orders_data_path = \"C:/Users/parij/OneDrive/Desktop/git_practice/UnORG_supply_chain_ml/order_data_last_six_month.xlsx\"\n",
    "items_data_path = \"C:/Users/parij/OneDrive/Desktop/git_practice/UnORG_supply_chain_ml/associated_order_item_data_last_six_month.xlsx\"\n",
    "\n",
    "orders = pd.read_excel(orders_data_path)\n",
    "order_items = pd.read_excel(items_data_path)\n",
    "# Merge them on order_id\n",
    "merged = pd.merge(order_items, orders, on='order_id', how='inner')\n",
    "\n",
    "merged['order_date'] = pd.to_datetime(merged['order_date'])\n",
    "\n",
    "def create_customer_product_features(df):\n",
    "    \"\"\"\n",
    "    Create features describing customer-product relationships\n",
    "    \"\"\"\n",
    "    # Get latest date in dataset for recency calculations\n",
    "    latest_date = df['order_date'].max()\n",
    "\n",
    "    # Group by customer-product pairs\n",
    "    cp_features = df.groupby(['customer_id', 'item_name']).agg({\n",
    "        'order_date': [\n",
    "            'count',  # Number of times ordered\n",
    "            'max',    # Last order date\n",
    "            lambda x: (latest_date - x.max()).days  # Recency\n",
    "        ],\n",
    "        'quantity': [\n",
    "            'sum',  # Total quantity ordered\n",
    "            'mean', # Average order size\n",
    "            'std'   # Variability in order size\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Flatten column names\n",
    "    cp_features.columns = ['_'.join(col).strip('_') for col in cp_features.columns.values]\n",
    "    cp_features = cp_features.reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    cp_features.rename(columns={\n",
    "        'order_date_count': 'order_frequency',\n",
    "        'order_date_max': 'last_order_date',\n",
    "        'order_date_<lambda_0>': 'days_since_last_order',\n",
    "        'quantity_sum': 'total_quantity',\n",
    "        'quantity_mean': 'avg_quantity',\n",
    "        'quantity_std': 'quantity_std'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Fill missing values for std (occurs when only ordered once)\n",
    "    cp_features['quantity_std'] = cp_features['quantity_std'].fillna(0)\n",
    "\n",
    "    return cp_features\n",
    "\n",
    "# Apply the function to create customer-product features\n",
    "customer_product_features = create_customer_product_features(merged)\n",
    "print(\"\\nCustomer-Product Features:\")\n",
    "print(customer_product_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qApIcUdX1IQI",
    "outputId": "86d3e4dd-15e9-43e4-e0be-fc6d398d2353"
   },
   "outputs": [],
   "source": [
    "def add_customer_features(df, cp_features):\n",
    "    \"\"\"\n",
    "    Add customer-level features to enhance predictions\n",
    "    \"\"\"\n",
    "    # Create customer-level aggregations\n",
    "    customer_features = df.groupby('customer_id').agg({\n",
    "        'order_id': 'nunique',  # Number of orders\n",
    "        'item_name': 'nunique', # Number of unique products\n",
    "        'quantity': 'sum',      # Total quantity ordered\n",
    "        'order_date': ['min', 'max', 'nunique']  # First, last, and number of order dates\n",
    "    })\n",
    "\n",
    "    # Flatten column names\n",
    "    customer_features.columns = ['_'.join(col).strip('_') for col in customer_features.columns.values]\n",
    "    customer_features = customer_features.reset_index()\n",
    "\n",
    "    # Calculate average order frequency (days between first and last order ÷ number of orders)\n",
    "    customer_features['avg_days_between_orders'] = (\n",
    "        (customer_features['order_date_max'] - customer_features['order_date_min']).dt.days /\n",
    "        customer_features['order_date_nunique']\n",
    "    )\n",
    "\n",
    "    # Fill infinities (if customer only ordered once)\n",
    "    customer_features['avg_days_between_orders'] = customer_features['avg_days_between_orders'].replace(np.inf, 0)\n",
    "\n",
    "    # Rename columns\n",
    "    customer_features.rename(columns={\n",
    "        'order_id_nunique': 'total_orders',\n",
    "        'item_name_nunique': 'unique_products',\n",
    "        'quantity_sum': 'customer_total_quantity',\n",
    "        'order_date_nunique': 'unique_order_dates'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Merge with customer-product features\n",
    "    features_df = pd.merge(cp_features, customer_features, on='customer_id', how='left')\n",
    "\n",
    "    return features_df\n",
    "\n",
    "# Apply the function to add customer-level features\n",
    "enhanced_features = add_customer_features(merged, customer_product_features)\n",
    "print(\"\\nEnhanced Features with Customer Data:\")\n",
    "print(enhanced_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nwh5lcaM1NLN",
    "outputId": "709e6748-c24c-49ff-f6d6-60a731d350cf"
   },
   "outputs": [],
   "source": [
    "def add_product_features(df, features_df):\n",
    "    \"\"\"\n",
    "    Add product-level features for better prediction\n",
    "    \"\"\"\n",
    "    # Create product-level aggregations\n",
    "    product_features = df.groupby('item_name').agg({\n",
    "        'customer_id': 'nunique',  # Number of unique customers\n",
    "        'order_id': 'nunique',     # Number of orders\n",
    "        'quantity': ['sum', 'mean'] # Total quantity and average quantity\n",
    "    })\n",
    "\n",
    "    # Flatten column names\n",
    "    product_features.columns = ['_'.join(col).strip('_') for col in product_features.columns.values]\n",
    "    product_features = product_features.reset_index()\n",
    "\n",
    "    # Calculate product popularity score (weighted by both customer count and order count)\n",
    "    product_features['popularity_score'] = (\n",
    "        product_features['customer_id_nunique'] *\n",
    "        product_features['order_id_nunique']\n",
    "    ) / product_features['customer_id_nunique'].max() / product_features['order_id_nunique'].max()\n",
    "\n",
    "    # Rename columns\n",
    "    product_features.rename(columns={\n",
    "        'customer_id_nunique': 'customer_count',\n",
    "        'order_id_nunique': 'order_count',\n",
    "        'quantity_sum': 'product_total_quantity',\n",
    "        'quantity_mean': 'product_avg_quantity'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Merge with existing features\n",
    "    features_df = pd.merge(features_df, product_features, on='item_name', how='left')\n",
    "\n",
    "    return features_df\n",
    "\n",
    "# Apply the function to add product-level features\n",
    "complete_features = add_product_features(merged, enhanced_features)\n",
    "print(\"\\nComplete Features with Product Data:\")\n",
    "print(complete_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfVpeg4M1NHz",
    "outputId": "1466ce27-256a-4ee5-e700-5683729e0098"
   },
   "outputs": [],
   "source": [
    "def add_interaction_features(features_df):\n",
    "    \"\"\"\n",
    "    Add interaction features that capture combined behavior\n",
    "    \"\"\"\n",
    "    # Calculate how much of a customer's total quantity is this specific product\n",
    "    features_df['product_share'] = features_df['total_quantity'] / features_df['customer_total_quantity']\n",
    "\n",
    "    # Calculate order frequency relative to customer's overall ordering pattern\n",
    "    features_df['relative_order_frequency'] = features_df['order_frequency'] / features_df['total_orders']\n",
    "\n",
    "    # Customer's tendency to reorder (based on recency and frequency)\n",
    "    features_df['reorder_score'] = features_df['order_frequency'] / (features_df['days_since_last_order'] + 1)\n",
    "\n",
    "    # Product affinity (combine order frequency with quantity)\n",
    "    features_df['product_affinity'] = features_df['order_frequency'] * features_df['total_quantity']\n",
    "\n",
    "    # Calculate expected days until next order\n",
    "    features_df['expected_days_to_next_order'] = (\n",
    "        features_df['avg_days_between_orders'] -\n",
    "        features_df['days_since_last_order']\n",
    "    ).clip(lower=0)\n",
    "\n",
    "    return features_df\n",
    "\n",
    "# Apply the function to add interaction features\n",
    "final_features = add_interaction_features(complete_features)\n",
    "print(\"\\nFinal Features with Interactions:\")\n",
    "print(final_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EA_LGMy41NEZ",
    "outputId": "fce258f2-9424-4048-aad8-694af1b97f85"
   },
   "outputs": [],
   "source": [
    "def prepare_training_data(df, features_df, cutoff_date, prediction_window=14):\n",
    "    \"\"\"\n",
    "    Prepare data for training the prediction models\n",
    "    \"\"\"\n",
    "    # Define the target window\n",
    "    prediction_start = cutoff_date + pd.Timedelta(days=1)\n",
    "    prediction_end = cutoff_date + pd.Timedelta(days=prediction_window)\n",
    "\n",
    "    print(f\"Preparing to predict orders from {prediction_start} to {prediction_end}\")\n",
    "\n",
    "    # Get actual orders in the target period for training\n",
    "    target_orders = df[\n",
    "        (df['order_date'] >= prediction_start) &\n",
    "        (df['order_date'] <= prediction_end)\n",
    "    ]\n",
    "\n",
    "    # Create target variables\n",
    "    # 1. Was this product ordered by this customer in the prediction window?\n",
    "    ordered_pairs = target_orders.groupby(['customer_id', 'item_name']).size().reset_index()\n",
    "    ordered_pairs.columns = ['customer_id', 'item_name', 'order_count']\n",
    "    ordered_pairs['was_ordered'] = 1\n",
    "\n",
    "    # 2. How much was ordered in the prediction window?\n",
    "    quantity_ordered = target_orders.groupby(['customer_id', 'item_name'])['quantity'].sum().reset_index()\n",
    "\n",
    "    # Merge targets with features\n",
    "    training_data = pd.merge(\n",
    "        features_df,\n",
    "        ordered_pairs[['customer_id', 'item_name', 'was_ordered']],\n",
    "        on=['customer_id', 'item_name'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    training_data['was_ordered'] = training_data['was_ordered'].fillna(0)\n",
    "\n",
    "    # Merge quantity information where applicable\n",
    "    training_data = pd.merge(\n",
    "        training_data,\n",
    "        quantity_ordered,\n",
    "        on=['customer_id', 'item_name'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    training_data['quantity'] = training_data['quantity'].fillna(0)\n",
    "\n",
    "    # Select features for modeling\n",
    "    feature_cols = [\n",
    "        'order_frequency', 'days_since_last_order', 'total_quantity',\n",
    "        'avg_quantity', 'quantity_std', 'total_orders', 'unique_products',\n",
    "        'customer_total_quantity', 'customer_count', 'order_count',\n",
    "        'product_total_quantity', 'product_avg_quantity', 'popularity_score',\n",
    "        'product_share', 'relative_order_frequency', 'reorder_score',\n",
    "        'product_affinity', 'expected_days_to_next_order'\n",
    "    ]\n",
    "\n",
    "    return training_data, feature_cols\n",
    "\n",
    "# Define a cutoff date for training (using part of the data)\n",
    "# This should be a date that leaves enough future data for validation\n",
    "max_date = merged['order_date'].max()\n",
    "cutoff_date = max_date - pd.Timedelta(days=14)  # Use data up to 14 days before the last date\n",
    "\n",
    "# Prepare training data\n",
    "training_data, feature_cols = prepare_training_data(merged, final_features, cutoff_date)\n",
    "print(\"\\nTraining Data prepared with targets:\")\n",
    "print(training_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rhkUNff41NBy",
    "outputId": "fc2b8034-886d-48a7-9d02-0cebc643491c"
   },
   "outputs": [],
   "source": [
    "def build_product_selection_model(training_data, feature_cols):\n",
    "    \"\"\"\n",
    "    Build a model to predict which products a customer will order\n",
    "    \"\"\"\n",
    "    # Prepare features and target for the product selection model\n",
    "    X = training_data[feature_cols]\n",
    "    y = training_data['was_ordered']\n",
    "\n",
    "    # Check class distribution\n",
    "    class_counts = np.bincount(y.astype(int))\n",
    "    print(f\"Class distribution - Not ordered: {class_counts[0]}, Ordered: {class_counts[1]}\")\n",
    "\n",
    "    # Calculate class weight to handle imbalance\n",
    "    weight_ratio = class_counts[0] / class_counts[1] if class_counts[1] > 0 else 10\n",
    "    class_weight = {0: 1, 1: min(weight_ratio, 10)}  # Cap at 10 to avoid extreme weights\n",
    "    print(f\"Using class weights: {class_weight}\")\n",
    "\n",
    "    # Split data for training and validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        class_weight=class_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    print(\"\\nProduct Selection Model Evaluation:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "    # Feature importance\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(\"\\nTop 5 important features:\")\n",
    "    print(importance.head(5))\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "# Build the product selection model\n",
    "selection_model, selection_scaler = build_product_selection_model(training_data, feature_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukjfjhT01M-u",
    "outputId": "4ebb9f8a-a702-4206-d6c9-1f2ca8b06e16"
   },
   "outputs": [],
   "source": [
    "%pip install joblib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3KA044v1M4o",
    "outputId": "ed2dee8f-40ba-44f0-e377-fda81062f436"
   },
   "outputs": [],
   "source": [
    "joblib.dump(selection_model,'C:/Users/parij/OneDrive/Desktop/git_practice/UnORG_supply_chain_ml/models/selection_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kA6WIj5e1My1",
    "outputId": "e54d5ed8-f32b-4cb6-8317-4479c73dcd69"
   },
   "outputs": [],
   "source": [
    "def build_quantity_prediction_model(training_data, feature_cols):\n",
    "    \"\"\"\n",
    "    Build a model to predict the quantity of each product a customer will order\n",
    "    \"\"\"\n",
    "    # Filter to only products that were ordered (quantity > 0)\n",
    "    quantity_data = training_data[training_data['was_ordered'] == 1].copy()\n",
    "\n",
    "    if len(quantity_data) == 0:\n",
    "        print(\"No products were ordered in the target period. Cannot build quantity model.\")\n",
    "        return None, None\n",
    "\n",
    "    # Prepare features and target for the quantity prediction model\n",
    "    X = quantity_data[feature_cols]\n",
    "    y = quantity_data['quantity']\n",
    "\n",
    "    # Split data for training and validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42\n",
    "    )\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train model\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Round predictions to nearest integer (can't order partial quantities)\n",
    "    y_pred_rounded = np.round(y_pred).clip(1)\n",
    "\n",
    "    print(\"\\nQuantity Prediction Model Evaluation:\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred_rounded):.2f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rounded)):.2f}\")\n",
    "    print(f\"R²: {r2_score(y_test, y_pred_rounded):.4f}\")\n",
    "\n",
    "    # Feature importance\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    print(\"\\nTop 5 important features for quantity prediction:\")\n",
    "    print(importance.head(5))\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "# Build the quantity prediction model\n",
    "quantity_model, quantity_scaler = build_quantity_prediction_model(training_data, feature_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecGknK3b1MqG",
    "outputId": "460c085c-3bc2-4f23-a826-fa835fc9357d"
   },
   "outputs": [],
   "source": [
    "joblib.dump(quantity_model,'C:/Users/parij/OneDrive/Desktop/git_practice/UnORG_supply_chain_ml/models/quantity_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIVnvP5l1MeY",
    "outputId": "971a44f9-9d86-472d-d123-621da3c8ee21"
   },
   "outputs": [],
   "source": [
    "def predict_future_orders(features_df, selection_model, quantity_model,\n",
    "                         selection_scaler, quantity_scaler, feature_cols, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict which products each customer will order and in what quantity\n",
    "    \"\"\"\n",
    "    # Get features for prediction\n",
    "    X_pred = features_df[feature_cols]\n",
    "\n",
    "    # Scale features\n",
    "    X_pred_scaled = selection_scaler.transform(X_pred)\n",
    "\n",
    "    # Predict product selection probability\n",
    "    selection_proba = selection_model.predict_proba(X_pred_scaled)[:, 1]\n",
    "\n",
    "    # Add predictions to features dataframe\n",
    "    prediction_results = features_df[['customer_id', 'item_name']].copy()\n",
    "    prediction_results['selection_probability'] = selection_proba\n",
    "    prediction_results['will_order'] = (selection_proba >= threshold).astype(int)\n",
    "\n",
    "    # Filter to products predicted to be ordered\n",
    "    will_order = prediction_results[prediction_results['will_order'] == 1].copy()\n",
    "\n",
    "    if len(will_order) == 0:\n",
    "        print(\"No products predicted to be ordered\")\n",
    "        return prediction_results\n",
    "\n",
    "    # Predict quantities for selected products\n",
    "    if quantity_model is not None:\n",
    "        X_qty_pred = X_pred.loc[will_order.index]\n",
    "        X_qty_pred_scaled = quantity_scaler.transform(X_qty_pred)\n",
    "\n",
    "        quantity_pred = quantity_model.predict(X_qty_pred_scaled)\n",
    "        will_order['predicted_quantity'] = np.round(quantity_pred).clip(1).astype(int)\n",
    "    else:\n",
    "        # If no quantity model, use historical average\n",
    "        will_order['predicted_quantity'] = features_df.loc[will_order.index, 'avg_quantity'].fillna(1).round().clip(1).astype(int)\n",
    "\n",
    "    # Merge back with full results\n",
    "    prediction_results = pd.merge(\n",
    "        prediction_results,\n",
    "        will_order[['customer_id', 'item_name', 'predicted_quantity']],\n",
    "        on=['customer_id', 'item_name'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    prediction_results['predicted_quantity'] = prediction_results['predicted_quantity'].fillna(0).astype(int)\n",
    "\n",
    "    # Count predicted orders\n",
    "    orders_count = len(will_order)\n",
    "    customers_count = will_order['customer_id'].nunique()\n",
    "    products_count = will_order['item_name'].nunique()\n",
    "\n",
    "    print(f\"\\nPredicted {orders_count} orders across {customers_count} customers for {products_count} products\")\n",
    "\n",
    "    return prediction_results\n",
    "\n",
    "# Generate predictions\n",
    "predictions = predict_future_orders(\n",
    "    final_features,\n",
    "    selection_model,\n",
    "    quantity_model,\n",
    "    selection_scaler,\n",
    "    quantity_scaler,\n",
    "    feature_cols\n",
    ")\n",
    "\n",
    "print(\"\\nSample predictions:\")\n",
    "print(predictions.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "i5U3R7yT1MTV",
    "outputId": "6365b2e9-d9bb-4ee4-cc55-fcce679a5048"
   },
   "outputs": [],
   "source": [
    "def aggregate_demand_by_product(predictions):\n",
    "    \"\"\"\n",
    "    Aggregate demand by product for inventory planning\n",
    "    \"\"\"\n",
    "    # Filter to rows with predicted orders\n",
    "    ordered = predictions[predictions['will_order'] == 1]\n",
    "\n",
    "    # Group by product\n",
    "    product_demand = ordered.groupby('item_name').agg({\n",
    "        'predicted_quantity': 'sum',\n",
    "        'customer_id': 'nunique'\n",
    "    }).reset_index()\n",
    "\n",
    "    product_demand.columns = ['item_name', 'total_predicted_quantity', 'unique_customers']\n",
    "    product_demand = product_demand.sort_values('total_predicted_quantity', ascending=False)\n",
    "\n",
    "    print(\"\\nTop products by predicted demand:\")\n",
    "    print(product_demand.head(10))\n",
    "\n",
    "    # Visualize top products\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_products = product_demand.head(15)\n",
    "    sns.barplot(x='total_predicted_quantity', y='item_name', data=top_products)\n",
    "    plt.title('Top 15 Products by Predicted Demand')\n",
    "    plt.xlabel('Predicted Quantity')\n",
    "    plt.ylabel('Product')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return product_demand\n",
    "\n",
    "# Aggregate demand by product\n",
    "product_demand = aggregate_demand_by_product(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzmsXLZo2R42",
    "outputId": "a1d9fc46-01f3-432a-cc6d-8df91570c070"
   },
   "outputs": [],
   "source": [
    "def generate_customer_recommendations(predictions, top_n=5):\n",
    "    \"\"\"\n",
    "    Generate top product recommendations for each customer\n",
    "    \"\"\"\n",
    "    # Get customers with predictions\n",
    "    customers = predictions['customer_id'].unique()\n",
    "\n",
    "    all_recommendations = []\n",
    "\n",
    "    for customer in customers:\n",
    "        # Get customer's predictions\n",
    "        customer_preds = predictions[predictions['customer_id'] == customer].copy()\n",
    "\n",
    "        # Sort by selection probability\n",
    "        customer_preds = customer_preds.sort_values('selection_probability', ascending=False)\n",
    "\n",
    "        # Get top N recommendations\n",
    "        top_recommendations = customer_preds.head(top_n)\n",
    "\n",
    "        # Only include products with non-zero probability\n",
    "        top_recommendations = top_recommendations[top_recommendations['selection_probability'] > 0]\n",
    "\n",
    "        all_recommendations.append(top_recommendations)\n",
    "\n",
    "    # Combine all recommendations\n",
    "    if all_recommendations:\n",
    "        recommendations_df = pd.concat(all_recommendations)\n",
    "\n",
    "        print(f\"\\nGenerated recommendations for {len(customers)} customers\")\n",
    "\n",
    "        # Display sample recommendations for a few customers\n",
    "        sample_customers = recommendations_df['customer_id'].unique()[:3]\n",
    "        for customer in sample_customers:\n",
    "            print(f\"\\nRecommendations for customer {customer}:\")\n",
    "            print(recommendations_df[recommendations_df['customer_id'] == customer])\n",
    "\n",
    "        return recommendations_df\n",
    "    else:\n",
    "        print(\"No recommendations generated\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Generate customer recommendations\n",
    "customer_recommendations = generate_customer_recommendations(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5JzZFWF2XBm"
   },
   "outputs": [],
   "source": [
    "customer_recommendations.to_csv('customer_recommendations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mzeTKtv-24l4",
    "outputId": "7ca833ac-1e20-4d5c-80f3-788f25c113d9"
   },
   "outputs": [],
   "source": [
    "def run_sku_forecasting_pipeline(df, cutoff_date=None, prediction_window=14):\n",
    "    \"\"\"\n",
    "    Run the complete SKU-level demand forecasting pipeline\n",
    "    \"\"\"\n",
    "    # If no cutoff date is provided, use the latest date in the dataset\n",
    "    if cutoff_date is None:\n",
    "        cutoff_date = df['order_date'].max() - pd.Timedelta(days=prediction_window)\n",
    "\n",
    "    print(f\"Running forecast with cutoff date: {cutoff_date}\")\n",
    "\n",
    "    # Only use data prior to cutoff date for training\n",
    "    historical_data = df[df['order_date'] <= cutoff_date].copy()\n",
    "\n",
    "    # Creating features\n",
    "    print(\"\\nEngineering features...\")\n",
    "    cp_features = create_customer_product_features(historical_data)\n",
    "    features_with_customer = add_customer_features(historical_data, cp_features)\n",
    "    complete_features = add_product_features(historical_data, features_with_customer)\n",
    "    final_features = add_interaction_features(complete_features)\n",
    "\n",
    "    # Prepare training data\n",
    "    print(\"\\nPreparing training data...\")\n",
    "    training_data, feature_cols = prepare_training_data(df, final_features, cutoff_date, prediction_window)\n",
    "\n",
    "    # Build models\n",
    "    print(\"\\nBuilding prediction models...\")\n",
    "    selection_model, selection_scaler = build_product_selection_model(training_data, feature_cols)\n",
    "    quantity_model, quantity_scaler = build_quantity_prediction_model(training_data, feature_cols)\n",
    "\n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions...\")\n",
    "    predictions = predict_future_orders(\n",
    "        final_features, selection_model, quantity_model,\n",
    "        selection_scaler, quantity_scaler, feature_cols\n",
    "    )\n",
    "\n",
    "    # Aggregate demand for inventory planning\n",
    "    print(\"\\nAggregating demand for inventory planning...\")\n",
    "    product_demand = aggregate_demand_by_product(predictions)\n",
    "\n",
    "    # Generate customer recommendations\n",
    "    print(\"\\nGenerating customer recommendations...\")\n",
    "    customer_recommendations = generate_customer_recommendations(predictions)\n",
    "\n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'product_demand': product_demand,\n",
    "        'customer_recommendations': customer_recommendations,\n",
    "        'models': {\n",
    "            'selection_model': selection_model,\n",
    "            'quantity_model': quantity_model,\n",
    "            'selection_scaler': selection_scaler,\n",
    "            'quantity_scaler': quantity_scaler\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "results = run_sku_forecasting_pipeline(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8CkpGjO3VrS"
   },
   "outputs": [],
   "source": [
    "def calculate_inventory_requirements(predictions_df, product_demand_df, current_stock_df=None):\n",
    "    \"\"\"\n",
    "    Calculate inventory requirements for next 14 days.\n",
    "    \"\"\"\n",
    "    # Generate future date range\n",
    "    start_date = pd.to_datetime(\"2025-04-15\")  # Use current date from context\n",
    "    date_range = pd.date_range(start=start_date, periods=14, name='order_date')\n",
    "\n",
    "    # Create full product-date grid\n",
    "    products = predictions_df['item_name'].unique()\n",
    "    full_grid = pd.MultiIndex.from_product([products, date_range], names=['item_name', 'order_date']).to_frame(index=False)\n",
    "\n",
    "    # Merge predictions with date grid\n",
    "    predictions_df = full_grid.merge(predictions_df, on=['item_name'], how='left')\n",
    "    predictions_df['predicted_quantity'] = predictions_df['predicted_quantity'].fillna(0)\n",
    "\n",
    "    # Rest of original logic remains unchanged\n",
    "    daily_demand = predictions_df.groupby(['item_name', 'order_date'])['predicted_quantity'].sum().unstack().fillna(0)\n",
    "\n",
    "    projection = daily_demand.sum(axis=1).to_frame(name='14_day_demand')\n",
    "\n",
    "    if current_stock_df is not None:\n",
    "        projection = projection.merge(current_stock_df,\n",
    "                                     left_index=True,\n",
    "                                     right_on='item_name',\n",
    "                                     how='left')\n",
    "        projection['current_stock'] = projection['current_stock'].fillna(0)\n",
    "    else:\n",
    "        projection['current_stock'] = 0\n",
    "\n",
    "    projection['safety_stock'] = (projection['14_day_demand'] * 0.2).round().astype(int) + 10\n",
    "\n",
    "    projection['recommended_order'] = np.where(\n",
    "        projection['current_stock'] < projection['14_day_demand'] + projection['safety_stock'],\n",
    "        (projection['14_day_demand'] + projection['safety_stock'] - projection['current_stock']).clip(lower=0),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    return projection.reset_index()[['item_name', '14_day_demand',\n",
    "                                    'current_stock', 'safety_stock',\n",
    "                                    'recommended_order']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnNeBjVA4Hva"
   },
   "outputs": [],
   "source": [
    "# Example: current_stock is a DataFrame with columns ['item_name', 'current_stock']\n",
    "inventory_plan = calculate_inventory_requirements(\n",
    "    predictions_df=predictions[predictions['will_order'] == 1][['item_name', 'predicted_quantity']],\n",
    "    product_demand_df=None,  # Not needed if using predictions directly\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxNCY3nd86x6",
    "outputId": "165b37b5-ac1f-4d0b-a2be-5c66b4f6c930"
   },
   "outputs": [],
   "source": [
    "print(inventory_plan.head(10))  # Shows the top 10 products needing replenishment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aepKHPbe89aB"
   },
   "outputs": [],
   "source": [
    "inventory_plan.to_csv('inventory_plan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aik4MI2S9jGX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
