{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDQU8-v8C25_",
    "outputId": "f273d973-4a14-49c2-9e66-079b88eaa22a"
   },
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- Load Data ---\n",
    "orders_data_path = \"C:/Users/parij/OneDrive/Desktop/git_practice/UnORG_supply_chain_ml/data/order_data_last_six_month.xlsx\"\n",
    "items_data_path = \"C:/Users/parij/OneDrive/Desktop/git_practice/UnORG_supply_chain_ml/data/associated_order_item_data_last_six_month.xlsx\"\n",
    "\n",
    "orders_df = pd.read_excel(orders_data_path)\n",
    "items_df = pd.read_excel(items_data_path)\n",
    "\n",
    "# --- Preprocessing ---\n",
    "orders_df['order_date'] = pd.to_datetime(orders_df['order_date'], dayfirst=True)\n",
    "\n",
    "# Base customer-date grid\n",
    "customer_orders = orders_df[['customer_id', 'order_date']].copy()\n",
    "customer_orders['order_placed'] = 1\n",
    "\n",
    "min_date = orders_df['order_date'].min()\n",
    "max_date = orders_df['order_date'].max()\n",
    "date_range = pd.date_range(min_date, max_date)\n",
    "customers = customer_orders['customer_id'].unique()\n",
    "\n",
    "grid = pd.MultiIndex.from_product([customers, date_range], names=[\"customer_id\", \"order_date\"])\n",
    "full_df = pd.DataFrame(index=grid).reset_index()\n",
    "full_df = full_df.merge(customer_orders, on=[\"customer_id\", \"order_date\"], how=\"left\")\n",
    "full_df['order_placed'] = full_df['order_placed'].fillna(0).astype(int)\n",
    "\n",
    "# --- Rolling Features ---\n",
    "full_df = full_df.sort_values(by=['customer_id', 'order_date'])\n",
    "\n",
    "# Compute days since last order safely and correctly\n",
    "last_order_tracker = full_df.groupby('customer_id')['order_placed'].transform(\n",
    "    lambda x: x.ne(0).cumsum().where(x == 1)\n",
    ")\n",
    "full_df['days_since_last_order'] = (\n",
    "    last_order_tracker.groupby(full_df['customer_id']).ffill().groupby(full_df['customer_id']).cumcount()\n",
    ")\n",
    "full_df['days_since_last_order'] = full_df['days_since_last_order'].fillna(999)\n",
    "\n",
    "\n",
    "full_df['orders_past_7d'] = full_df.groupby('customer_id')['order_placed'].transform(lambda x: x.rolling(7).sum())\n",
    "full_df['orders_past_14d'] = full_df.groupby('customer_id')['order_placed'].transform(lambda x: x.rolling(14).sum())\n",
    "full_df.fillna({'orders_past_7d': 0, 'orders_past_14d': 0}, inplace=True)\n",
    "\n",
    "# --- Date Features ---\n",
    "full_df['day_of_week'] = full_df['order_date'].dt.dayofweek\n",
    "full_df['is_weekend'] = full_df['day_of_week'].isin([5, 6]).astype(int)\n",
    "full_df['month'] = full_df['order_date'].dt.month\n",
    "full_df['day'] = full_df['order_date'].dt.day\n",
    "\n",
    "# --- Cumulative Behavior ---\n",
    "full_df['cumulative_orders'] = full_df.groupby('customer_id')['order_placed'].cumsum()\n",
    "order_counts = full_df.groupby('customer_id')['order_placed'].sum()\n",
    "active_days = full_df.groupby('customer_id').size()\n",
    "full_df['avg_order_frequency'] = full_df['customer_id'].map((order_counts / active_days).to_dict())\n",
    "\n",
    "# --- Merge Items with Orders ---\n",
    "orders_items_merged = items_df.merge(orders_df[['order_id', 'customer_id', 'order_date']], on='order_id', how='left')\n",
    "orders_items_merged['order_date'] = pd.to_datetime(orders_items_merged['order_date'], dayfirst=True)\n",
    "\n",
    "# Most common item per customer\n",
    "most_common_item = (\n",
    "    orders_items_merged.groupby(['customer_id', 'item_name'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    "    .sort_values(['customer_id', 'count'], ascending=[True, False])\n",
    "    .drop_duplicates('customer_id')\n",
    "    .set_index('customer_id')['item_name']\n",
    "    .to_dict()\n",
    ")\n",
    "full_df['top_item'] = full_df['customer_id'].map(most_common_item)\n",
    "le = LabelEncoder()\n",
    "full_df['top_item_encoded'] = le.fit_transform(full_df['top_item'].fillna('Unknown'))\n",
    "\n",
    "# Average days between orders\n",
    "order_dates = orders_df.sort_values(by='order_date')[['customer_id', 'order_date']]\n",
    "avg_days_between = (\n",
    "    order_dates.groupby('customer_id')['order_date']\n",
    "    .apply(lambda x: x.diff().dt.days.dropna().mean())\n",
    "    .to_dict()\n",
    ")\n",
    "full_df['avg_days_between_orders'] = full_df['customer_id'].map(avg_days_between)\n",
    "\n",
    "# Distinct items ordered\n",
    "distinct_items = (\n",
    "    orders_items_merged.groupby('customer_id')['item_name']\n",
    "    .nunique()\n",
    "    .to_dict()\n",
    ")\n",
    "full_df['distinct_items_ordered'] = full_df['customer_id'].map(distinct_items)\n",
    "\n",
    "# Fill final NaNs\n",
    "full_df.fillna({\n",
    "    'avg_days_between_orders': 999,\n",
    "    'distinct_items_ordered': 0\n",
    "}, inplace=True)\n",
    "\n",
    "# --- Prepare for Modeling ---\n",
    "feature_cols = [\n",
    "    'days_since_last_order', 'orders_past_7d', 'orders_past_14d',\n",
    "    'day_of_week', 'is_weekend', 'month', 'day',\n",
    "    'cumulative_orders', 'avg_order_frequency',\n",
    "    'top_item_encoded', 'avg_days_between_orders',\n",
    "    'distinct_items_ordered'\n",
    "]\n",
    "\n",
    "X = full_df[feature_cols]\n",
    "y = full_df['order_placed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# --- Train Model LightGBM Classifier ---\n",
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: Predict probabilities for next 14 days (you can extend this as needed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkLBndelR6vp"
   },
   "source": [
    "**Saves the Model Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dA0GnjsNRK_",
    "outputId": "0d13a09d-9c47-4c13-e475-a18038550ee7"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the Model\n",
    "joblib.dump(clf, 'C:/Users/parij/OneDrive/Desktop/git_practice/UnORG_supply_chain_ml/models/Order_identification.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWrnXFXVFhgw"
   },
   "source": [
    "**Report for various Classification Models**\n",
    "\n",
    "Gives classification report for various classification model.\n",
    "\n",
    "\n",
    "\n",
    "1.   Random Forest\n",
    "2.   Logistic Regression\n",
    "3.   KNN\n",
    "4.   XGBoost\n",
    "5.   LightGBM  \n",
    "\n",
    "The Best one among these 5 is ***LightGBM*** which gives an accuracy of 0.933. So, we are using LightGBM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJGMu1-JFgs-",
    "outputId": "602d2a21-1492-427f-a631-144dd57c22db"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000, class_weight='balanced'),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': lgb.LGBMClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\" Results for {name}:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQN3vWfVSjtb"
   },
   "source": [
    "**Generates Probability for next 14 Days**\n",
    "\n",
    "Gives a CSV file including each customer_id and their respective probabilities of ordering the products in next 14 days.\n",
    "\n",
    "This CSV is saved as \"order_probability_next_14_days.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "faVIqzkTD46c",
    "outputId": "672fac1f-53b0-43a1-8c61-2f3aeafdb492"
   },
   "outputs": [],
   "source": [
    "# Get latest known features per customer\n",
    "latest_features = full_df.sort_values(\"order_date\").groupby(\"customer_id\").tail(1).set_index(\"customer_id\")\n",
    "\n",
    "# Generate next 14 days\n",
    "from datetime import timedelta\n",
    "future_dates = pd.date_range(full_df['order_date'].max() + timedelta(days=1), periods=14)\n",
    "customers = latest_features.index.unique()\n",
    "\n",
    "# Step 3: Create customer Ã— date grid\n",
    "future_grid = pd.MultiIndex.from_product([customers, future_dates], names=[\"customer_id\", \"order_date\"]).to_frame(index=False)\n",
    "\n",
    "# Step 4: Copy static features from latest record\n",
    "for feature in [\n",
    "    'days_since_last_order', 'orders_past_7d', 'orders_past_14d',\n",
    "    'cumulative_orders', 'avg_order_frequency',\n",
    "    'top_item_encoded', 'avg_days_between_orders',\n",
    "    'distinct_items_ordered'\n",
    "]:\n",
    "    future_grid[feature] = future_grid['customer_id'].map(latest_features[feature])\n",
    "\n",
    "# Step 5: Add time-based features based on order_date\n",
    "future_grid['day_of_week'] = future_grid['order_date'].dt.dayofweek\n",
    "future_grid['is_weekend'] = future_grid['day_of_week'].isin([5, 6]).astype(int)\n",
    "future_grid['month'] = future_grid['order_date'].dt.month\n",
    "future_grid['day'] = future_grid['order_date'].dt.day\n",
    "\n",
    "# Step 6: Predict\n",
    "X_future = future_grid[feature_cols]  # same features used for training\n",
    "future_grid['order_probability'] = clf.predict_proba(X_future)[:, 1]\n",
    "\n",
    "# Step 7: Save only desired output\n",
    "final_output = future_grid[['customer_id', 'order_date', 'order_probability']]\n",
    "final_output.to_csv(\"data/order_probability_next_14_days.csv\", index=False)\n",
    "\n",
    "# Display sample\n",
    "final_output.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
